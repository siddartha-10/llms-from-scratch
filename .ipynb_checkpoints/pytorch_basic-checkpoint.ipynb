{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # to check the pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available()) # to check if the mps is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# creating pytorch tensors\n",
    "\n",
    "tensor0d = torch.tensor(1)\n",
    "print(tensor0d)\n",
    "\n",
    "tensor1d = torch.tensor([1,2,3])\n",
    "print(tensor1d)\n",
    "\n",
    "tensor2d = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(tensor2d)\n",
    "\n",
    "tensor3d = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(tensor3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the dataype of the tensor\n",
    "tensor0d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor = torch.tensor([1.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# when the values are int then the default type is always torch.int64, when the values are float the default is torch.float32\n",
    "print(float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# to change the datatype we use .to function\n",
    "tensor0d_float = tensor0d.to(torch.float32)\n",
    "print(tensor0d_float.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the shape we use .shape\n",
    "tensor2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change the shape of the tensor we .reshape and we can also use the .view\n",
    "tensor2d_reshaped = tensor2d.reshape([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal matrix\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "transposed matrix\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "# .T is used to get the transpose of a matrix\n",
    "m1 = torch.tensor([[1,2],[3,4]])\n",
    "m2 = m1.T\n",
    "\n",
    "print(\"Orginal matrix\")\n",
    "print(m1)\n",
    "print(\"transposed matrix\")\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 14],\n",
      "        [14, 20]]) matrix multiplication using matmul\n",
      "tensor([[10, 14],\n",
      "        [14, 20]]) matrix multiplication using @\n"
     ]
    }
   ],
   "source": [
    "# to do matrix multiplication we can use .matmul and also @\n",
    "m3 = m2.matmul(m1)\n",
    "m4 = m2@m1\n",
    "print(m3, \"matrix multiplication using matmul\")\n",
    "print(m4, \"matrix multiplication using @\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Gradients in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = w1*x1 + b\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a,y)\n",
    "\n",
    "gradient_loss_w1 = grad(loss,w1,retain_graph=True)\n",
    "gradient_loss_b = grad(loss,b,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)  This is the gradient of loss W.R.T w1\n",
      "(tensor([-0.0817]),)  This is the gradient of loss W.R.T b\n"
     ]
    }
   ],
   "source": [
    "print(gradient_loss_w1, \" This is the gradient of loss W.R.T w1\")\n",
    "print(gradient_loss_b, \" This is the gradient of loss W.R.T b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above process we have done everything manually it is useful for debugging but pytroch has something very simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = w1*x1 + b\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a,y)\n",
    "\n",
    "loss.backward()\n",
    "print(w1.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code implementing a classic multilayer perceptron with two hidden layers.\n",
    "\n",
    "1) We use the torch.nn.Module to build our own architecture.\n",
    "2) We use the init constructor to define the network layers and forward method to see how the inputs pass and interact.\n",
    "3) We use the .backwards method to inside of the training loop to calculate the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_inputs, 30),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            torch.nn.Linear(20, num_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model) # this is used to see the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2213\n"
     ]
    }
   ],
   "source": [
    "# To check the number of trainable parameter's\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0329,  0.0665,  0.0982,  ...,  0.1395,  0.1274, -0.0592],\n",
      "        [-0.1240, -0.0373, -0.0909,  ..., -0.1108, -0.0905, -0.0663],\n",
      "        [-0.0901, -0.1250,  0.0210,  ..., -0.0275, -0.0608, -0.1197],\n",
      "        ...,\n",
      "        [ 0.0226,  0.0968, -0.0249,  ..., -0.0012,  0.0424, -0.0984],\n",
      "        [ 0.0661,  0.0175,  0.1297,  ...,  0.0275,  0.1058,  0.1107],\n",
      "        [-0.1247,  0.0631, -0.0927,  ..., -0.0347, -0.0386,  0.0465]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# NeuralNetwork(\n",
    "#   (layers): Sequential(\n",
    "#     (0): Linear(in_features=50, out_features=30, bias=True)\n",
    "#     (1): ReLU()\n",
    "#     (2): Linear(in_features=30, out_features=20, bias=True)\n",
    "#     (3): ReLU()\n",
    "#     (4): Linear(in_features=20, out_features=3, bias=True)\n",
    "#   )\n",
    "# )\n",
    "\n",
    "# To access the paramerters for any layer the above network \n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# For reproducability purposes we can use manual_seed\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(50,3)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1670,  0.1001, -0.1219]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,50))\n",
    "out = model(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1670,  0.1001, -0.1219]])\n"
     ]
    }
   ],
   "source": [
    "# why we use this during inference is because with grad it will slow down the process. This tells pytroch to not keep track of the \n",
    "# gradients hence faster inference.\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2983, 0.3896, 0.3121]])\n"
     ]
    }
   ],
   "source": [
    "# we used softmax to get the class membership\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(x), dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Efficient Data Loaders\n",
    "1) The custom dataset class is used to instantiate objects that define how each data record is loaded\n",
    "2) The dataloader class is used to assemble and shuffle the data into batches etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a toy dataset\n",
    "x_train = torch.tensor([\n",
    "    [-1.2,3.1],\n",
    "    [-0.9,2.9],\n",
    "    [-0.5,2.6],\n",
    "    [2.3,-1.1],\n",
    "    [2.7,-1.5]\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0,0,0,1,1])\n",
    "\n",
    "x_test = torch.tensor([\n",
    "    [-0.8,2.8],\n",
    "    [2.6,-1.6]\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset class\n",
    "1) The init constructor is used to take the features and labels it maybe filepath, objects, database connectors etc\n",
    "2) The getitem method is used to return exactly one feature and it's corresponding label at a particular index.\n",
    "3) The len method is used to return the length of you train or test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.features = x\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_x, one_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "train_ds = ToyDataset(x_train, y_train)\n",
    "test_ds = ToyDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle = True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_ds,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the above we can see in the 3rd batch there is only one tensor but we need to 2, because the training dataset has odd number of \n",
    "## Records it will not help in convering of training, hence we will drop the last batch, drop_last = True.\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle = True,\n",
    "    num_workers= 0, # This is used for parallel data preprocessing, if it is zero then the model has to wait for the data batch to be \n",
    "    # available, if it is greater than one the the x,y is always ready and in queue since multiple workers are working on processing data.\n",
    "    drop_last= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\",x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | 000/002 | Train Loss: 0.75\n",
      "Epoch: 001/003 | 001/002 | Train Loss: 0.65\n",
      "Epoch: 002/003 | 000/002 | Train Loss: 0.44\n",
      "Epoch: 002/003 | 001/002 | Train Loss: 0.13\n",
      "Epoch: 003/003 | 000/002 | Train Loss: 0.03\n",
      "Epoch: 003/003 | 001/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs = 2, num_outputs = 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad() # this is used to prevent gradient accumulation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "             f\" | {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "             f\" | Train Loss: {loss:.2f}\"\n",
    "        )\n",
    "\n",
    "    # model.eval() this is optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need to add model.train() and model.eval()\n",
    "Ans) Becuase the model behaves differently while training and during evaluation, while training we need dropouts and normalizations but while\n",
    "inference or testing we do not need those and it is always a better practice to include them in our code, to avoid unexpected behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8569, -4.1618],\n",
      "        [ 2.5382, -3.7548],\n",
      "        [ 2.0944, -3.1820],\n",
      "        [-1.4814,  1.4816],\n",
      "        [-1.7176,  1.7342]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(x_train)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9991,     0.0009],\n",
      "        [    0.9982,     0.0018],\n",
      "        [    0.9949,     0.0051],\n",
      "        [    0.0491,     0.9509],\n",
      "        [    0.0307,     0.9693]])\n"
     ]
    }
   ],
   "source": [
    "# to obtain the class membership probabilities we apply softmax\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0.0\n",
    "\n",
    "    for idx, (features,labels) in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions\n",
    "        correct = correct + torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return (correct / total_examples).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "# what does state_dict() do is that it will map the layers with respect to their trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "# what does load_state_dict do is that it will apply the parameters obtained from torch.load to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Computations on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1,2,3,4])\n",
    "tensor2 = torch.tensor([1,2,3,4,])\n",
    "print(tensor1 + tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6, 8], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# We use .to() function to place these tensors on to the mps or gpu device.\n",
    "tensor1 = torch.tensor([1,2,3,4]).to(\"mps\")\n",
    "tensor2 = torch.tensor([1,2,3,4]).to(\"mps\")\n",
    "print(tensor1 + tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop on single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | 001/002 | Train Loss: 0.75\n",
      "Epoch: 001/003 | 001/002 | Train Loss: 0.65\n",
      "Epoch: 002/003 | 001/002 | Train Loss: 0.44\n",
      "Epoch: 002/003 | 001/002 | Train Loss: 0.13\n",
      "Epoch: 003/003 | 001/002 | Train Loss: 0.03\n",
      "Epoch: 003/003 | 001/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for idx, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "             f\" | {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "             f\" | Train Loss: {loss:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.87 µs ± 37 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Excerise A.4 to compare the matrix multiplication timings on gpu and cpu\n",
    "a = torch.rand(100,200).to(torch.float32)\n",
    "b = torch.rand(100,200).to(torch.float32).T\n",
    "%timeit a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.6 µs ± 252 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "a_mps = torch.rand(100,200).to(torch.float32).to(\"mps\")\n",
    "b_mps = torch.rand(100,200).to(torch.float32).to(\"mps\").T\n",
    "%timeit a_mps @ b_mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with multiple GPU'S\n",
    "##### Q) Why do we need multiple GPU'S\n",
    "Ans) We can reduce the training time significantly, it is useful in model development stage because we have to finetune the model\n",
    "architecture and also parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP (distributed data parellel) :- it is used to split the input data across multiple available devices and process the subsets of the\n",
    "# data simultaneously.\n",
    "# Let's consider we have 2 gpu's each of the gpu will have model, and then in every training iteration each model will receive a mini-batch \n",
    "# from the data loader we use DistributedSampler(to avoid non-duplplication of the minbatches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
