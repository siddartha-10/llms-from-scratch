{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e68a86-4816-44a0-a07c-a9c20c38e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df0dfa2-0d29-420b-8c6f-b75251c58cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1af7574-ae6d-4b60-ba17-1b8d8c31f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0 \n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(self.context_length, self.context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.w_key(x) # Applying key matrix\n",
    "        values = self.w_value(x) # Applying value matrix\n",
    "        queries = self.w_query(x)  # Applying query matrix\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # Reshaping keys so we can apply attention to all the batches at once rather than splitting them and then applying attention\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) # Reshaping values so we can apply attention to all the batches at once rather than splitting them and then applying attention\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # Reshaping queries so we can apply attention to all the batches at once rather than splitting them and then applying attention\n",
    "\n",
    "        keys = keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        queries = queries.transpose(1,2)\n",
    "\n",
    "        attention_scores = queries @ keys.transpose(2, 3) # Calculating attention scores\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens] # Applying -inf to the upper triangular matrix so softmax will zero out the values\n",
    "        attention_scores = attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attention_weights = torch.softmax(attention_scores / (keys.shape[-1]**0.5), dim=-1) # Applying softmax\n",
    "        attention_weights = self.dropout(attention_weights) # Applying dropout\n",
    "        context_vector = (attention_weights @ values).transpose(1, 2) # Calculating context vector\n",
    "        context_vector = context_vector.contiguous().view(b, num_tokens, self.d_out) # Reshaping context vector\n",
    "        context_vector = self.out_proj(context_vector) # Applying output projection layer\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9788b1-5f83-49dc-a4fd-608f5ffa8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim=True)\n",
    "        var = x.var(dim = -1, keepdim=True, unbiased=False)\n",
    "        out_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale*out_norm + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a80847d-c763-4d33-a455-b882a5335f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*cfg['emb_dim'], cfg['emb_dim']),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba5bab1-51dd-4587-98e7-cfeaec8bd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'],\n",
    "            dropout = cfg['dropout_rate'],\n",
    "            num_heads = cfg['num_heads'],\n",
    "            qkv_bias = cfg['qkv_bias'],\n",
    "            context_length = cfg['context_length']\n",
    "        )\n",
    "        self.FeedForward = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['dropout_rate'])\n",
    "\n",
    "    def forward(self,x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.FeedForward(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27426857-b913-4db8-b2ef-5dfd54717955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['dropout_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias = False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721e8135-9433-49ac-b356-720fe3b0dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,\n",
    "    'emb_dim': 768,\n",
    "    'context_length': 256,\n",
    "    'n_layers': 12,\n",
    "    'num_heads': 12,\n",
    "    'dropout_rate': 0.1,\n",
    "    'qkv_bias': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff0e478-2624-4ffa-851a-f568e289a513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c5d08f-3770-40a1-a270-8f274240174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa544d65-a4e8-4ba1-b293-56a61880aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## text_to_token_ids and token_ids_to_text\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # adding the batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # removing the batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e446beb-b9c3-40b3-8edc-5e748688b68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you 960esame WindsorFE Keith awaitedSer GaelListMine\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "start_content = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(start_content, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c995b-5bcc-4299-a60d-73acb97a6b1d",
   "metadata": {},
   "source": [
    "### Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "086158ba-b691-434e-9f2d-b965ba3b9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"every effort moves\"\n",
    "text2 = \"I really like\"\n",
    "target1 = \" effort moves you\"\n",
    "target2 = \" really like chocolate\"\n",
    "\n",
    "t1_tensor = text_to_token_ids(text1, tokenizer)\n",
    "t2_tensor = text_to_token_ids(text2, tokenizer)\n",
    "\n",
    "t3_tensor = text_to_token_ids(target1, tokenizer)\n",
    "t4_tensor = text_to_token_ids(target2, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0175a01a-7c4b-4b16-91be-feb893568bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16833,  3626,  6100]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bcf675f-f843-4f48-adbe-092385afb1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  40, 1107,  588]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b607eb68-2538-47c2-9ab9-620d534aee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3626, 6100,  345]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cffcb5a-e18e-4b84-9d1d-502778707cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a5af1f6-9e47-4a04-9ddd-8a1250d1e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([\n",
    "    [16833,  3626,  6100],\n",
    "    [40, 1107,  588]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5e49318-f119-4c11-8929-9409b9e08ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345],\n",
    "    [588, 428, 11311]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "934f0987-55ba-44a0-80a6-536031215826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65f88734-1a43-49df-b993-c0b2939370b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: \n",
      " tensor([[[13207],\n",
      "         [  552],\n",
      "         [42826]],\n",
      "\n",
      "        [[18236],\n",
      "         [34817],\n",
      "         [ 7055]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs: \\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7caa056f-a307-478c-a29c-a1ed8127c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_b1 = token_ids_to_text(targets[0], tokenizer)\n",
    "tatget_b1_model = token_ids_to_text(token_ids[0].flatten(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "031bcb91-484d-40a9-a56d-4f1432f1e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " effort moves you\n",
      "hole compNetflix\n"
     ]
    }
   ],
   "source": [
    "print(target_b1)\n",
    "print(tatget_b1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e719055-79a6-4a42-8f06-4e3a03f459ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ba9e39-c715-470f-86f6-3c2c88bcec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d654178d-82cc-4f48-8593-1db1c1dcfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0549e-05, 2.7952e-05, 8.2801e-06]) \n",
      " tensor([1.7212e-05, 1.5561e-05, 5.2184e-06])\n"
     ]
    }
   ],
   "source": [
    "print(target_probas_1, \"\\n\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f7c031c-94ab-45ce-a8d9-9033a114afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.8926, -10.4850, -11.7017, -10.9699, -11.0707, -12.1633])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9a45542-a387-4649-a587-9631c0444728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.0472)\n"
     ]
    }
   ],
   "source": [
    "ave_log_probas = torch.mean(log_probas)\n",
    "print(ave_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a646ff03-38e5-4ba8-9e35-b9c13c5da886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.0472)\n"
     ]
    }
   ],
   "source": [
    "neg_ave_log_probas = ave_log_probas * -1\n",
    "print(neg_ave_log_probas) # this is called as cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2583af8e-e6ac-4ebd-b09c-02458663ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d77e3af0-2903-4900-b854-09ca90aee62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 50257])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits = logits.flatten(0,1)\n",
    "targets = targets.flatten()\n",
    "print(logits.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3233d07e-a8cc-41f7-8e40-1a3430e5cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.0472)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e672c05-0246-4115-9531-0df853e9ba73",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "=> It is a measure often used alongside croos entropy loss to evaluate the performance of the models. It can provide a more interpretable way to understand the uncertainity of a model in predicting the next token in a sequence\n",
    "\n",
    "=> Lower perplexity means the output predicted output is closer to the actual output.\n",
    "\n",
    "=> perplexity = torch.exp(loss) ex:- it gives 47678 that means the model is not sure which one of the 47678 tokens in the vocab to generate as the next token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f7ca3-b356-48b9-8aee-184844d52643",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4d0630f-119d-4669-af9f-63a51df159ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/siddartha/Desktop/github/llms-from-scratch/Chapter_2_Working_with_text_data/the_verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ec118b5-76d4-4085-b1d7-e2ce547d7477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: \n",
      " 20479\n",
      "Total tokens: \n",
      " 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Total characters: \\n\", total_characters)\n",
    "print(\"Total tokens: \\n\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63e41172-96b4-4904-82e3-954752dddcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1b148a-3167-4a4d-b405-be5054343aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class GPTDatasetv1(Dataset):\n",
    "    def __init__(self, text, stride, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunks = token_ids[i:i+max_length]\n",
    "            target_chunks = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunks))\n",
    "            self.target_ids.append(torch.tensor(target_chunks))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75d740fe-731c-4d7e-8e2a-d6a057adf39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text, batch_size, max_length, stride, shuffle=False, drop_last=True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetv1(text=text, max_length=max_length, stride=stride, tokenizer=tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f25db85c-3a54-4200-9e64-438e0f026bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    text=train_data, \n",
    "    batch_size=2, \n",
    "    max_length = GPT_CONFIG_124M[\"context_length\"], \n",
    "    stride = GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    text = val_data,\n",
    "    batch_size=2,\n",
    "    max_length = GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last = True,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffa7affc-6a85-49af-a196-974875d0e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader: \n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader: \")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83fd699c-a8bd-4fb4-8075-98c9872de1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loader: \n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Loader: \")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "869f1e20-fb9e-4cf7-bdda-d0952313b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ecf6fbe-6e0b-451a-a9a1-c8a99d60a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1a4992f-ae85-4242-bc07-2fc7c71a526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to compute the training and validation loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
    "    total_loss = 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss+=loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e1aa732-0424-4608-b09d-e880ac621af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: \n",
      " 10.99716133541531\n",
      "Validation Loss: \n",
      " 10.98913860321045\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training Loss: \\n\", train_loss)\n",
    "print(\"Validation Loss: \\n\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601de626-6889-474a-836a-93c7f33a1749",
   "metadata": {},
   "source": [
    "### Typical Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e3d011c-cc32-4ef4-bcc0-ea0afbef02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen+= input_batch.numel()\n",
    "            global_step+=1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"EP {epoch+1} (Step {global_step:06d}):\"\n",
    "                     f\"Train loss {train_loss:3f}, val loss {val_loss:3f}\")\n",
    "        generate_and_print_sample(model, train_loader.dataset.tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "307e4fe1-4e48-46a1-b669-6719dacc5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7943f31b-8458-476a-9bc4-24787eab4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_content, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model,\n",
    "            idx = encoded,\n",
    "            max_new_tokens = 50,\n",
    "            context_size = context_size,\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\",\" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3bbc9b6-d477-4fa3-ac43-5dbd31b30317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d47b9860-d423-4e1f-a84e-110468c18cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP 1 (Step 000000):Train loss 10.133675, val loss 9.986797\n",
      "EP 1 (Step 000005):Train loss 7.744055, val loss 8.369277\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "EP 2 (Step 000010):Train loss 6.367939, val loss 7.049547\n",
      "EP 2 (Step 000015):Train loss 6.013133, val loss 6.582771\n",
      "Every effort moves you, the, the, the, the, the, the, the. \", the, the, the,, the, the, the, the, the, the, the, the, the, the, the, the, the\n",
      "EP 3 (Step 000020):Train loss 6.008183, val loss 6.537977\n",
      "EP 3 (Step 000025):Train loss 4.547883, val loss 6.366274\n",
      "Every effort moves you, and I had the picture. \"I, and I had been the picture, and I had been the picture, and he was. I had the the picture. I had the picture. I had been the picture. \"I he\n",
      "EP 4 (Step 000030):Train loss 5.118431, val loss 6.342582\n",
      "EP 4 (Step 000035):Train loss 4.470731, val loss 6.319545\n",
      "Every effort moves you knowburn, and I was a--I was his pictures a little. \"I was a little--and here are was a little. \"Oh, I had been. \"I had been, I had been. \"I\n",
      "EP 5 (Step 000040):Train loss 3.223626, val loss 6.347466\n",
      "Every effort moves you know it was not a little a--I was his pictures.   \"Oh, I was--and here are the donkey, and I was his pictures--as I had been. I had the donkey, and it.   \n",
      "EP 6 (Step 000045):Train loss 3.298949, val loss 6.170409\n",
      "EP 6 (Step 000050):Train loss 2.690572, val loss 6.200033\n",
      "Every effort moves you know; and in a little wild--I felt, and I felt in a little: \"Yes, and in the Riv, and Mrs.       \"--I had always _mine_--the, I was his\n",
      "EP 7 (Step 000055):Train loss 2.018901, val loss 6.212557\n",
      "EP 7 (Step 000060):Train loss 1.605332, val loss 6.226192\n",
      "Every effort moves you know; and to have my hostess was--I looked up his painting.                    \"Oh, I, the donkey. \"There were days, his\n",
      "EP 8 (Step 000065):Train loss 1.619823, val loss 6.288808\n",
      "EP 8 (Step 000070):Train loss 0.878469, val loss 6.266217\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the head to look up at the sketch of the donkey. \"There were days when I\n",
      "EP 9 (Step 000075):Train loss 0.794676, val loss 6.390813\n",
      "EP 9 (Step 000080):Train loss 0.516743, val loss 6.455936\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Victor Grindle was, in fact, becoming the man of the moment--as Jack himself, I had again run over from the picture--because he's when I\n",
      "EP 10 (Step 000085):Train loss 0.382098, val loss 6.511046\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0004, weight_decay = 0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5, eval_iter=1, start_context=\"Every effort moves you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "475eb526-1ced-45f5-8879-387883479ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training Losses\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle = \"-.\", label = \"Validation Losses\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc = \"upper right\")\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha = 0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02e629f4-88f9-424e-9b39-e997bc9df415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd70c78-d9e9-45fd-9ee6-5b73e7f15fb3",
   "metadata": {},
   "source": [
    "### Decoding strategies to control randomness\n",
    "1) temperature scaling\n",
    "2) top-k-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed116f52-62a8-45f5-b766-2066fa48ede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5102dbb-3c93-4f0f-88df-042c789099c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokens_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "decode_text = token_ids_to_text(tokens_ids, tokenizer)\n",
    "print(decode_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd03b35-0b51-4eff-a6e9-1edc87c0a8e3",
   "metadata": {},
   "source": [
    "### Temperature Scaling\n",
    "1) it is a technique that adds a probabilistic selection process to the next-token generation task\n",
    "Previously we have used the torch.argmax() to get the highest probability this is called as greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b73d4d96-1c83-4d63-b484-cede3ad384ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d94647d-7e46-4186-8600-c269af09ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_vocab = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0841294d-f24b-41b4-bec4-b926d2f1d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65e5ee57-179b-4006-a07f-1e71b9cdb0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2543b9b-00ac-4b00-9bdb-ad02971ba3b6",
   "metadata": {},
   "source": [
    "The above answer will always be forward because the probability of the logits is more than the other, this is called as the greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88f44828-b3fd-4c32-9150-ef881b8e8f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "## Replacing the torch.argmax to torch.multinomial\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples = 1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e87f841-5209-4c5a-84b5-658b3a7a079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer x 73\n",
      "every x 0\n",
      "effort x 0\n",
      "forward x 582\n",
      "inches x 2\n",
      "moves x 0\n",
      "pizza x 0\n",
      "toward x 343\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples = 1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{inverse_vocab[i]} x {freq}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2514d0df-1af5-454d-99d4-1b8bf1a042e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a994a24f-a53f-43ee-94f2-6196cd7adcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, t) for t in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, t in enumerate(temperatures):\n",
    "    rects = ax.bar(x+i*bar_width, scaled_probas[i], bar_width, label=f'Temperature = {t}')\n",
    "ax.set_ylabel('probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f07a5-d626-40df-8072-9428791f4d68",
   "metadata": {},
   "source": [
    "### Top-K Sampling\n",
    "1) In this technique what we do is that we will select the top-k only and we will mask out the other tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09ecb855-e07d-4d33-86f9-9c1834fa871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: \n",
      " tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: \n",
      " tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits: \\n\", top_logits)\n",
    "print(\"Top positions: \\n\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "674ae2cc-d5d4-4524-9f57-50f0f5ecbf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition = next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float('-inf')),\n",
    "    other = next_token_logits,\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8855f28-33d9-4f66-8d71-9055c4dc1827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad7cfc-d21f-4044-9fc5-c2dc1e996cc7",
   "metadata": {},
   "source": [
    "### Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e47a4de3-e3c6-4ead-89da-974580c01d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature, top_k=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ae97ed8-22bb-447c-bfa6-ac5c377af2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "tokens_ids = generate(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=25,\n",
    "    temperature = 1.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba33fe22-0c84-4b52-9fb6-3d82a69a91f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5485a496-bd2b-4a6a-bea0-b9bc4d24300f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345,  460,  553,  373,  530,  286,  262, 9074,   13,\n",
       "          402,  271, 3973, 1297, 9074,   13,  198]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b2ba646-2edb-434c-908a-148ed597e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you can,\" was one of the Mrs. Gisitely told Mrs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Output text: \\n\", token_ids_to_text(tokens_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfad8388-b11d-4463-9d18-00f105e1f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model weights\n",
    "torch.save(model.state_dict(), \"model_scratch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8336e82a-b18d-4f0f-9f4d-aa3011a40ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (FeedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the model weights\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model_scratch.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00ca6806-7605-4837-83ad-de9cc7492cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we plan to continue pretraining a model later, for example using the train_model_simple function. it's better to store the optimizer\n",
    "# weights as well becuase the AdamW uses the historic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e334336-02d2-42ae-9718-a6ea911eab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the optimizer weights use this\n",
    "torch.save({\n",
    "    \"model_state_dict\":model.state_dict(),\n",
    "    \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b953f2f9-51b8-4cb7-8670-f9185d9d6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91026605-317c-4473-919e-4b04c4e32c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x50930e650>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading OPENAI's Weights\n",
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fd3a5-1512-4589-8bcc-4366b2212f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|███████████████████████████| 77.0/77.0 [00:00<00:00, 29.7kiB/s]\n",
      "encoder.json: 100%|████████████████████████| 1.04M/1.04M [00:01<00:00, 570kiB/s]\n",
      "hparams.json: 100%|█████████████████████████| 90.0/90.0 [00:00<00:00, 34.7kiB/s]\n",
      "model.ckpt.data-00000-of-00001:  78%|█████▍ | 387M/498M [01:04<00:22, 4.94MiB/s]"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b23bd-41c5-4be1-a904-d78c4257d813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
